{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGBLdKsbgsNT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SJFTCvizUJBg",
    "outputId": "69d01729-6c18-48c8-e9ff-cd5f990e2cb7"
   },
   "outputs": [],
   "source": [
    "from skued import dmread\n",
    "import inpystem\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import utils.ssim as SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1AO5ZFogsNV"
   },
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K79eaKN4gsNX"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jyuXnSFBW8_"
   },
   "outputs": [],
   "source": [
    "def scale_image(img_np):\n",
    "    a = np.min(img_np)\n",
    "    b = np.max(img_np)\n",
    "    return 255/(b-a)*(img_np-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkHCEG1jKHbl"
   },
   "outputs": [],
   "source": [
    "def plot_spectre(img_np):\n",
    "    if img_np.shape[0] > 1:\n",
    "        img_np = scale_image(img_np)\n",
    "        columns = 2\n",
    "        rows = 1\n",
    "        f, axs = plt.subplots(rows,columns,figsize=(16,8))\n",
    "        \n",
    "        axs[0].imshow(img_np[0],cmap='gray')\n",
    "        axs[0].set_title('Spectrum[0]')\n",
    "\n",
    "        axs[1].imshow(img_np[1],cmap='gray')\n",
    "        axs[1].set_title('Spectrum[1]')\n",
    "    \n",
    "    else:\n",
    "        img_np = scale_image(img_np)\n",
    "        columns = 1\n",
    "        rows = 1\n",
    "        f, axs = plt.subplots(rows,columns,figsize=(8,8))\n",
    "        plt.imshow(img_np[0],cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7G0aJarLlgYi"
   },
   "outputs": [],
   "source": [
    "def plot_final(out_np,orig_np):\n",
    "    print_metrics(torch.tensor(out_np).unsqueeze(0).float(), torch.tensor(orig_np).unsqueeze(0).float())\n",
    "    a = np.min(orig_np)\n",
    "    b = np.max(orig_np)\n",
    "    out_np , orig_np = 255/(b-a)*(out_np-a) , 255/(b-a)*(orig_np-a)\n",
    "    print('                                                 --- ORIGINAL ---')\n",
    "    f = plot_spectre(orig_np)\n",
    "    print('                                                 --- OUTPUT ---')\n",
    "    f = plot_spectre(out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YY4CpvZTjHD"
   },
   "outputs": [],
   "source": [
    "def load_and_process_fc(path, PCA_th, p):\n",
    "    \n",
    "    '''\n",
    "       ____________________________ \n",
    "    /!\\ For fully completed images /!\\\n",
    "    \\¡/____________________________\\¡/\n",
    "    \n",
    "    Takes as inputs :\n",
    "    \n",
    "     - path : String corresponding to the path of your \".dm3\" or \".dm4\" data,\n",
    "     - PCA_th : Int corresponding to the number of wavelengths desired with the PCA,\n",
    "     - p : percentage of image you want to keep intact (0<p<1).\n",
    "     \n",
    "     The data's shape must be : Spectrum Size x m x n (where m and n matche with the size of the image).\n",
    "     \n",
    "     Returns :\n",
    "     \n",
    "     (The array shape is always as follows : Size x m x n)\n",
    "     \n",
    "     - full _image : A numpy Array of the full image with the principal wavelenghts (obtained thanks to a PCA),\n",
    "     - partial_image : A numpy Array of the partial image (PCA realized on it),\n",
    "     - mask : A numpy Array corresponding to the mask of (0, 1) used to hide the missing pixels of the image.\n",
    "     - l1 : A numpy array corresponding to the percentage (0<l<1) of variance explained by the Spectrum associated \n",
    "            for the full_image,\n",
    "     - l2 : A numpy array corresponding to the percentage (0<l<1) of variance explained by the Spectrum associated \n",
    "            for the partial_image,\n",
    "     - PCA1 : The object PCA used by inPystem in order to achieve the inverse PCA on the full image,\n",
    "     - PCA2 : The object PCA used by inPystem in order to achieve the inverse PCA on the partial image.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        img = dmread(path)\n",
    "    except:\n",
    "        print(\"File not found ! Edit your path or be sure to have skued.dmread as dmread.\")\n",
    "        \n",
    "    print(\"Image loaded with success !\")\n",
    "    \n",
    "    if len(np.shape(img))!=3 or np.shape(img)[0]==0 or np.shape(img)[1]==0 or np.shape(img)[2]==0:\n",
    "        raise ValueError(\"Format Invalid ! Expected an S x m x n array with \\\".dm3\\\" or \\\".dm4\\\" format\")\n",
    "    \n",
    "    try:\n",
    "        p = min(max(0,p),1)\n",
    "    except:\n",
    "        print('\"p\" must be a Double or a Float (or equivalent) between 0 and 1')\n",
    "    \n",
    "    try:\n",
    "        PCA_th = int(max(0,PCA_th))\n",
    "    except:\n",
    "        print('\"PCA_th\" must be an Integer between 1 and the Spectrum Size')\n",
    "    \n",
    "    m, n = np.shape(img)[1], np.shape(img)[2]\n",
    "    N = int(p*m*n)\n",
    "    mask = np.random.permutation([0]*(m*n-N)+[1]*N).reshape((m, n))\n",
    "    \n",
    "    print('Mask created with success !')\n",
    "    \n",
    "    if np.shape(img)[0]<PCA_th:\n",
    "        raise ValueError('Not enough Spectrum dimensions for the PCA.')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Y_1 = np.transpose(img, (1, 2, 0))\n",
    "        Y_2 = np.transpose(mask*img, (1, 2, 0))\n",
    "        PCA_1 = inpystem.tools.PCA.PcaHandler(Y_1, mask=None, PCA_transform=True, PCA_th = PCA_th, verbose=False)\n",
    "        full_img = np.transpose(PCA_1.direct(), (2, 0, 1))\n",
    "        \n",
    "        mfi = np.max(full_img)\n",
    "        mmfi = np.min(full_img)\n",
    "        full_img = 1/(mfi-mmfi)*(full_img-mmfi)\n",
    "        \n",
    "        PCA_2 = inpystem.tools.PCA.PcaHandler(Y_2, mask=mask, PCA_transform=True, PCA_th = PCA_th, verbose=False)\n",
    "        partial_img = mask*np.transpose(PCA_2.direct(), (2, 0, 1))\n",
    "        \n",
    "        mpi = np.max(partial_img)\n",
    "        mmpi = np.min(partial_img)\n",
    "        partial_img = 1/(mfi-mmfi)*(partial_img-mmfi)\n",
    "        \n",
    "        print('Both PCA done with success !')\n",
    "        \n",
    "        l1 = percentage_variance(img, mask)\n",
    "        l2 = percentage_variance(mask*img, mask)\n",
    "        \n",
    "        print('Both weights calculated with success !')\n",
    "    \n",
    "    return full_img, partial_img, mask, l1, l2, PCA_1, PCA_2\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def percentage_variance(img, mask):\n",
    "    \n",
    "    '''\n",
    "        Takes as inputs :\n",
    "            - img : A numpy array (The array shape is always as follows : Size x m x n),\n",
    "            - mask : A numpy array full of 0 & 1 corresponding to the mask --> It can be 'None'.\n",
    "            \n",
    "        Returns :\n",
    "            - lambdas : A numpy array corresponding to the percentage (0<l<1) of variance explained by the Spectrum associated.\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    if mask is None:\n",
    "        mask = np.array([[1]*n]*m)\n",
    "        \n",
    "    Y = np.transpose(mask*img, (1, 2, 0))\n",
    "    m, n, M = Y.shape\n",
    "    N = int(mask.sum())\n",
    "    P = m * n\n",
    "\n",
    "    nnz = np.flatnonzero(mask)\n",
    "    Yr = Y.reshape((n * m, M)).T\n",
    "\n",
    "    Yrm = np.tile(np.mean(Yr[:, nnz], axis=1), (P, 1)).T\n",
    "    Yrwm = Yr - Yrm\n",
    "    [d, V] = np.linalg.eig(np.cov(Yrwm[:, nnz]))\n",
    "\n",
    "    ind = np.argsort(d)[::-1]\n",
    "    d = d[ind]\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    plt.bar(list(range(1,21)),d[:20]/sum(d)*100)\n",
    "    plt.title('Percentage of data Explained by Eigen vector')\n",
    "    plt.xlabel('Eigen Values')\n",
    "    plt.ylabel('%')\n",
    "    \n",
    "    lambdas = d/sum(d)\n",
    "    \n",
    "    return lambdas\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def inverse_pca(img, PCA):\n",
    "    \n",
    "    '''\n",
    "    This function can do the reverse PCA of an image in order to restore all the spectrum.\n",
    "    \n",
    "        Takes as inputs :\n",
    "            - img : A numpy array (The array shape is always as follows : Size x m x n),\n",
    "            - PCA : The class PCA (from inPystem) used and returned by a function 'load_and_process_?'.\n",
    "            \n",
    "        Returns :\n",
    "            - recovered_img : The image with full recovery of the spectrum.\n",
    "    '''\n",
    "    \n",
    "    if len(np.shape(img))!=3  or np.shape(img)[1]==0 or np.shape(img)[2]==0:\n",
    "        raise ValueError(\"Format Invalid ! Expected an S x m x n numpy array.\")\n",
    "        \n",
    "    if np.shape(img)[0]==PCA.PCA_th:\n",
    "        raise ValueError(\"Spectral dimension does not match with the PCA.\")\n",
    "             \n",
    "    recovered_img = inpystem.tools.PCA.inverse(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "    print('Inverse PCA done with success !')\n",
    "    \n",
    "    return recovered_img\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def master_metric(real_image, filled_image, a, b, c, type_):\n",
    "    \n",
    "    '''\n",
    "        Takes as inputs :\n",
    "            \n",
    "            - real_image : The real image, format --> torch whose shape is (1,Spectrum_Size,m,n),\n",
    "            - filled_image : The image filled by the estimator, format --> torch whose shape is (1,Spectrum_Size,m,n),\n",
    "            \n",
    "            - a,b,c : 3 parameters a,b,c >= 0 such as if type_== 'sum', master_metric = a x PSNR + b x SSIM + c x SAD,\n",
    "                                                      if type_== 'product', master_metric = PSNR^a * SSIM^b * SAD^c,\n",
    "            - type_ : 'sum' (if so, a+b+c=1) or 'product'.\n",
    "            \n",
    "        Returns :\n",
    "        \n",
    "            Return a metric which is a combinaison of the PSNR, the SSIM and the SAD metric (if a=1 and b,c=(0,0), the metric\n",
    "            is equivalent to PSNR, if b=1 and a,c=(0,0), the metric is equivalent to SSIM and so on).\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        a, b, c = np.abs(a), np.abs(b), np.abs(c)\n",
    "    except:\n",
    "        print(\"The parameters a,b,c must be numbers.\")\n",
    "    if a+b+c==0:\n",
    "        raise ValueError(\"At least one parameter a,b or c should differ from 0.\")\n",
    "        \n",
    "    ssim = SSIM.ssim(filled_image, real_image)\n",
    "    loss_psnr = nn.MSELoss()\n",
    "    psnr = 1/8*torch.log10(255*255/loss_psnr(filled_image, real_image))\n",
    "    ri_f = torch.flatten(real_image)\n",
    "    fi_f = torch.flatten(filled_image)\n",
    "    sad = torch.dot(ri_f, fi_f)/(torch.norm(ri_f)*torch.norm(fi_f))\n",
    "    \n",
    "    if type_=='sum':\n",
    "        a, b, c = a/(a+b+c), b/(a+b+c), c/(a+b+c)\n",
    "        return a*psnr+b*ssim+c*sad\n",
    "         \n",
    "    elif type_=='product':\n",
    "        return psnr**a * ssim**b * sad**c\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"\\\"type_\\\" must be 'sum' or 'product'.\")\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def plot_spectra_comparison(real_image, filled_image):\n",
    "    \n",
    "    '''\n",
    "    Plot the differences between the real image and the predicted one among the spectrum kept by the PCA.\n",
    "    \n",
    "        Takes as inputs : \n",
    "            - real_image : A numpy array (The array shape is always as follows : Size x m x n),\n",
    "            - filled_image : A numpy array (The array shape is always as follows : Size x m x n).\n",
    "    '''\n",
    "    \n",
    "    if np.shape(real_image)!=np.shape(filled_image):\n",
    "        raise ValueError(\"Both images must have the same shape.\")\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [20, 20]\n",
    "    plt.figure()\n",
    "    S = np.shape(real_image)[0]\n",
    "    for i in range(S):\n",
    "        plt.subplot(S,2,i+1)\n",
    "        plt.imshow(real_image[i,:,:])\n",
    "        plt.title('Real Image, Spectrum n°:'+str(i))\n",
    "        plt.subplot(S,2,i+2)\n",
    "        plt.imshow(filled_image[i,:,:])\n",
    "        plt.title('Filled Image, Spectrum n°:'+str(i))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def plot_each_spectrum(img):\n",
    "    \n",
    "    '''\n",
    "    Plot the 10 first spectra of the image (bette doing a PCA first).\n",
    "    \n",
    "        Takes as inputs : \n",
    "            - img : A numpy array (The array shape is always as follows : Size x m x n).\n",
    "    '''\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [20, 20]\n",
    "    plt.figure()\n",
    "    S = np.shape(img)[0]\n",
    "    for i in range(min(S,10)):\n",
    "        plt.subplot(5,2,i+1)\n",
    "        plt.imshow(img[i,:,:])\n",
    "        plt.title('Spectrum n°:'+str(i))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def plot_colorized_spectrum(img):\n",
    "    \n",
    "    '''\n",
    "    Plot the 3 prime spectra as RGB, RBG, GRB, GBR, BRG, BGR.\n",
    "    \n",
    "        Takes as inputs : \n",
    "            - img : A numpy array (The array shape is always as follows : Size x m x n).\n",
    "    '''\n",
    "    \n",
    "    S = np.shape(img)[0]\n",
    "    if S<3:\n",
    "        raise ValueError(\"You need at least the 3 principal spectra obtained with a PCA.\")\n",
    "                \n",
    "    l = [[0,1,2], [0,2,1], [1,0,2], [1,2,0], [2,0,1], [2,1,0]]\n",
    "    \n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [20, 12]\n",
    "    plt.figure()\n",
    "    \n",
    "    for i in range(6):\n",
    "        plt.subplot(3,2,i+1)\n",
    "        plt.imshow(img[:,:,l[i]])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def load_and_process_p(path, PCA_th, mask):\n",
    "    \n",
    "    '''\n",
    "       ____________________\n",
    "    /!\\ For partial images /!\\\n",
    "    \\¡/____________________\\¡/\n",
    "    \n",
    "    Takes as inputs :\n",
    "    \n",
    "     - path : String corresponding to the path of your \".dm3\" or \".dm4\" data,\n",
    "     - PCA_th : Int corresponding to the number of wavelengths desired with the PCA,\n",
    "     - mask : A numpy Array corresponding to the mask of (0, 1) used to hide the missing pixels of the image.\n",
    "     \n",
    "     The data's shape must be : Spectrum Size x m x n (where m and n matche with the size of the image).\n",
    "     \n",
    "     Returns :\n",
    "     \n",
    "     (The array shape is as follows : Size x m x n)\n",
    "     \n",
    "     - partial_image : A numpy Array of the partial image (PCA realized on it),\n",
    "     - mask : A numpy Array corresponding to the mask of (0, 1) used to hide the missing pixels of the image,\n",
    "     - l : A numpy array corresponding to the percentage (0<l<1) of variance explained by the Spectrum,\n",
    "     - PCA_ : The object PCA used by inPystem in order to achieve the inverse PCA.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        img = dmread(path)\n",
    "    except:\n",
    "        print(\"File not found ! Edit your path or be sure to have skued.dmread as dmread.\")\n",
    "        \n",
    "    print(\"Image loaded with success !\")\n",
    "    \n",
    "    if len(np.shape(img))!=3 or np.shape(img)[0]==0 or np.shape(img)[1]==0 or np.shape(img)[2]==0:\n",
    "        raise ValueError(\"Format Invalid ! Expected an S x m x n array with \\\".dm3\\\" or \\\".dm4\\\" format\")\n",
    "            \n",
    "    if len(np.shape(mask))!=2 or np.shape(img)[1]!=np.shape(mask)[0] or np.shape(img)[2]!=np.shape(mask)[1]:\n",
    "        raise ValueError(\"Format Invalid ! Expected a m x n numpy array as mask.\")\n",
    "        \n",
    "    for i in range(np.shape(mask)[0]):\n",
    "        for j in range(np.shape(mask)[0]):\n",
    "            if np.isnan(mask[i,j]):\n",
    "                mask[i,j]=0\n",
    "                \n",
    "    for i in range(np.shape(mask)[0]):\n",
    "        for j in range(np.shape(mask)[0]):\n",
    "            if mask[i,j]!=0 and mask[i,j]!=1:\n",
    "                raise ValueError(\"The mask should only contain 0 & 1 values (or NaN instead of 0).\")\n",
    "    \n",
    "    try:\n",
    "        PCA_th = int(max(0,PCA_th))\n",
    "    except:\n",
    "        print('\"PCA_th\" must be an Integer between 1 and the Spectrum Size')\n",
    "    \n",
    "    if np.shape(img)[0]<PCA_th:\n",
    "        print('Not enough Spectrum dimensions for the PCA, the array is returned as it is.')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Y = np.transpose(mask*img, (1, 2, 0))\n",
    "                \n",
    "        PCA_ = inpystem.tools.PCA.PcaHandler(Y, mask=mask, PCA_transform=True, PCA_th = PCA_th, verbose=False)\n",
    "        partial_img = mask*np.transpose(PCA_.direct(), (2, 0, 1))\n",
    "        \n",
    "        print('PCA done with success !')\n",
    "        \n",
    "        mpi = np.max(partial_img)\n",
    "        mmpi = np.min(partial_img)\n",
    "        partial_img = 1/(mfi-mmfi)*(partial_img-mmfi)\n",
    "        \n",
    "        l = percentage_variance(img, mask)\n",
    "        \n",
    "        print('Weights calculated with success !')\n",
    "    \n",
    "    return partial_img, mask, l, PCA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0IrdJsKCkgi"
   },
   "outputs": [],
   "source": [
    "def print_metrics(real_image, filled_image):\n",
    "    psnr = master_metric(real_image, filled_image, 1, 0, 0, 'sum')\n",
    "    ssim = master_metric(real_image, filled_image, 0, 1, 0, 'sum')\n",
    "    sad = master_metric(real_image, filled_image, 0, 0, 1, 'sum')\n",
    "    print('SSIM : %.4f -- PSNR : %.4f -- SAD : %.4f' % (ssim,psnr,sad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_image\n",
      "filled_image\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e7b1e8afc60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'real_image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filled_image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-dcd5f7c535f4>\u001b[0m in \u001b[0;36mprint_metrics\u001b[0;34m(real_image, filled_image)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2d62a684b78e>\u001b[0m in \u001b[0;36mmaster_metric\u001b[0;34m(real_image, filled_image, a, b, c, type_)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one parameter a,b or c should differ from 0.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mloss_psnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mloss_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/isae/hackaton/eels-inpainting-team8/utils/ssim.py\u001b[0m in \u001b[0;36mssim\u001b[0;34m(img1, img2, window_size, size_average)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "print_metrics(*{'real_image':'test', 'filled_image':'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "gWR43xbiTpRa",
    "outputId": "6e8b1c36-b2e7-47af-b831-b183db3fc132"
   },
   "outputs": [],
   "source": [
    "full_pca_img, partial_pca_img, mask, l1, l2, PCA1, PCA2 = load_and_process_fc('data/HR-sample/spim4-2_ali.dm4',5,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfk19VEwYtrW"
   },
   "outputs": [],
   "source": [
    "img_var = np_to_torch(partial_pca_img).type(dtype)\n",
    "mask_var = np_to_torch(mask).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6hakx-OYcXc"
   },
   "outputs": [],
   "source": [
    "def closure():\n",
    "    \n",
    "    global i\n",
    "    \n",
    "    if param_noise:\n",
    "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "            n = n + n.detach().clone().normal_() * n.std() / 50\n",
    "    \n",
    "    net_input = net_input_saved\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        \n",
    "    out = net(net_input)\n",
    "\n",
    "    if loss == 'mse':\n",
    "        mse = torch.nn.MSELoss().type(dtype)\n",
    "        total_loss = mse(out * mask_var, img_var * mask_var)\n",
    "    elif loss == 'master_metric':\n",
    "        total_loss = -master_metric((out * mask_var), (img_var * mask_var), 1, 1, 1, 'product')\n",
    "    else:\n",
    "        raise ValueError(\"Input a correct loss name (among 'mse' | 'master_metric'\")\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    if grad_clipping:\n",
    "        for param in net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGnuPdgjYQVt"
   },
   "outputs": [],
   "source": [
    "num_iter = 3001\n",
    "show_every = 100\n",
    "figsize = 8\n",
    "reg_noise_std = 0.01\n",
    "param_noise = False\n",
    "\n",
    "loss = 'master_metric' # one of 'mse'|'master_metric'\n",
    "NET_TYPE = 'skip6' # one of skip_depth4|skip_depth2|ResNet\n",
    "OPTIMIZER = 'adamw' # one of 'adam'|'adamw'|'LBFGS'\n",
    "pad = 'reflection' # 'zero'\n",
    "\n",
    "grad_clipping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCXacRTvGZIG"
   },
   "outputs": [],
   "source": [
    "OPT_OVER = 'net'\n",
    "\n",
    "INPUT = 'noise'\n",
    "input_depth = partial_pca_img.shape[0]\n",
    "output_depth = partial_pca_img.shape[0]\n",
    "\n",
    "if 'skip' in NET_TYPE:\n",
    "    \n",
    "    depth = int(NET_TYPE[-1])\n",
    "    net = skip(input_depth, output_depth, \n",
    "            num_channels_down = [16, 16, 16][:depth],\n",
    "            num_channels_up =   [16, 16, 16][:depth],\n",
    "            num_channels_skip =    [16, 16, 16][:depth],  \n",
    "            filter_size_up = 5,filter_size_down = 5,  filter_skip_size=1,\n",
    "            upsample_mode='nearest', # downsample_mode='avg',\n",
    "            need1x1_up=False,\n",
    "            need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "    \n",
    "    LR = 0.01\n",
    "    \n",
    "elif NET_TYPE == 'resnet':\n",
    "    \n",
    "    net = ResNet(input_depth, output_depth, 4, 4, act_fun='LeakyReLU')\n",
    "    \n",
    "    LR = 0.01\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Select an architecture among skip_depth6 | skip_depth4 skip_depth2 | resnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Sy9BlSofHPQt",
    "outputId": "5a046267-ca07-429b-8c69-f770a4181220"
   },
   "outputs": [],
   "source": [
    "net = net.type(dtype)\n",
    "net_input = get_noise(input_depth, INPUT, partial_pca_img.shape[1:],var=1).type(dtype)\n",
    "\n",
    "# Compute number of parameters\n",
    "s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "print ('Number of params: %d' % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zuplMG2jgsN0",
    "outputId": "1fe705fc-f35e-4916-a9a7-7579f06d17ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "id": "wMXA8cj6gsN3",
    "outputId": "70ca0fb0-6df2-4b7e-fe2e-bb9db657cfec"
   },
   "outputs": [],
   "source": [
    "out_np = torch_to_np(net(net_input))\n",
    "plot_final(out_np,full_pca_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KPtRnmvI7I9"
   },
   "outputs": [],
   "source": [
    "a = {'1':1}\n",
    "b = a\n",
    "b['2']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '2': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.keys>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reverse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-27838a1bba7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reverse' is not defined"
     ]
    }
   ],
   "source": [
    "a =  reverse([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ColabPrior.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
